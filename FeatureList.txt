
Module 1:
    Blender exporter
    Camera space transformations
    Image read and write
Module 2:
    Ray intersection
    Acceleration hierarchy (BVH)

Raytracer Feature Breakdown
===========================

Blender Exporter
This feature allows scenes created in Blender to be exported into a custom text format compatible with the raytracer. Located in "raytracer/Blend/Export.py", this Python script automates the conversion of 3D geometry, camera settings, and lights. It ensures that complex scenes designed in a GUI environment can be parsed and rendered without manually writing scene files.

Bounding Volume Hierarchy (BVH) Acceleration
To optimize rendering speed, the system implements a Bounding Volume Hierarchy. This is toggled via the "--no-bvh" flag in "raytracer/Code/main.cpp" and initialized in the "Scene" constructor within "raytracer/Code/scene.h". By organizing scene objects into a tree structure (likely implemented in "raytracer/Code/acceleration/bvh.cpp"), the raytracer significantly reduces the number of intersection tests required for each ray.

Antialiasing (MSAA)
Multi-Sample Anti-Aliasing is implemented directly in the rendering loop within "raytracer/Code/main.cpp". Controlled by the "--aa" flag, the "main" function casts multiple rays per pixel ("SAMPLES_PER_PIXEL") with slight random offsets ("random_u", "random_v"). The resulting colors are averaged to smooth out jagged edges and reduce aliasing artifacts.

Blinn-Phong Shading
The core shading model uses the Blinn-Phong approximation for efficient specular highlights. Defined in "raytracer/Code/shading.h", the "calculate_specular" function computes the halfway vector between the light and view directions. This is combined with the "calculate_local_ad" function, which handles ambient and diffuse components using the material properties defined in "raytracer/Code/material.h".

Soft Shadows
The raytracer supports soft shadows using Monte Carlo sampling, enabled via the "--shadows" flag in "raytracer/Code/main.cpp". In "raytracer/Code/shading.h", the "calculate_local_ad" function casts shadow rays towards random points on a spherical light source ("random_point_on_light"). By averaging the results of these samples ("SHADOW_SAMPLES"), the system produces realistic penumbras rather than hard, binary shadows.

Texture Mapping
Material surfaces can be detailed using image textures, as defined in the "Material" struct in "raytracer/Code/material.h". The implementation in "raytracer/Code/shading.h" checks for a "texture" pointer; if present, it maps the hit point's UV coordinates to pixel coordinates on the texture image to determine the diffuse color, overriding the basic material color.

Parallel Rendering
To utilize multi-core processors, the application employs OpenMP for parallel execution. This is detected and enabled in "raytracer/Code/main.cpp" via the "--parallel" flag. The main loop iterating over the image height is decorated with "#pragma omp parallel for", allowing different scanlines of the image to be rendered simultaneously on separate threads.

Motion Blur
Motion blur is simulated by associating a time value with each ray. Enabled by the "--motion-blur" flag in "raytracer/Code/main.cpp", the system assigns a random time between 0.0 and "shutter_time" to each ray generated by the camera. This temporal sampling allows moving objects to appear blurred along their trajectory during the exposure frame.

Depth of Field (Defocus Blur)
This feature simulates the optical properties of a physical camera lens, allowing for specific focal planes and blurred backgrounds. It is implemented in the "Camera::generateRay" function within "raytracer/Code/camera.cpp". When a valid "f_stop" and "focal_distance" are parsed from the scene file in "raytracer/Code/scene.cpp", the camera replaces the standard pinhole model with a thin lens model. Instead of originating from a single point, rays are cast from random points across a virtual lens aperture (calculated using "random_in_unit_disk"), causing objects away from the "focal_distance" to appear out of focus.

Exposure Control
The system includes a basic tone-mapping feature controlled by the "--exposure" flag in "raytracer/Code/main.cpp". In "raytracer/Code/shading.h", the calculated light intensity is scaled by this exposure value. This allows the user to adjust the overall brightness of the rendered image to handle scenes with varying lighting intensities.

Fresnel Effect
Support for the Fresnel effect, which alters reflection strength based on the viewing angle, is indicated by the "--fresnel" flag in "raytracer/Code/main.cpp" and the boolean "m_fresnel_enabled" in "raytracer/Code/scene.h". This feature typically increases reflectivity at grazing angles, simulating the behavior of dielectric materials like glass or water.

Refraction and Transparency
The "Material" struct in "raytracer/Code/material.h" includes properties for "transparency" and "refractive_index". These fields allow the raytracer to simulate light passing through objects, bending rays according to physical indices of refraction (e.g., 1.52 for glass), enabling the rendering of realistic transparent objects.

Bump Mapping
Bump mapping simulates detailed surface relief by perturbing the geometric normal based on texture data without adding polygons. This is implemented in "raytracer/Code/shapes/sphere.cpp" within the "intersect" method, where a Tangent-Bitangent-Normal (TBN) matrix is constructed dynamically using the sphere's UV coordinates. The system reads gradient values from a specific bump map texture (parsed in "raytracer/Code/scene.cpp") to alter the normal vector stored in the "HitRecord", which is subsequently used by the shading logic in "raytracer/Code/shading.h" to create realistic lighting highlights and shadows.

Cube UV Mapping
The cube shape implements a custom UV mapping strategy to wrap a single texture across all six faces using an unfolded "cross" layout. Implemented in the "Cube::intersect" method within "raytracer/Code/shapes/cube.cpp", the logic first identifies the hit face by analyzing the object-space intersection point relative to the cube's bounds. It then computes local planar coordinates and applies specific offsets—such as mapping the "Top" face to the (1,2) grid position and "Front" to (1,1)—to normalize the UVs onto a 4x3 grid, enabling the use of standard skybox-style textures.

HDR
This feature implements Image-Based Lighting (IBL) using High Dynamic Range (HDR) environment maps, specifically supporting the .pfm (Portable FloatMap) format. Implemented primarily in raytracer/Code/HDRImage.cpp and raytracer/Code/tracer.h, the system allows rays that miss all scene geometry to sample a 360° panoramic background.

The implementation includes a robust custom PFM parser (HDRImage::load) capable of handling variable header whitespace, comment skipping, and endianness detection based on the file's scale factor. For rendering, the system maps ray direction vectors to spherical (latitude-longitude) coordinates using get_sphere_uv in tracer.h. These coordinates are then used to perform bilinear interpolation HDRImage::sample by interpolating horizontally and then vertically across a 2x2 square of pixels, ensuring smooth reflections and background rendering even at high resolutions. This allows glossy and transparent objects to reflect complex, real-world lighting environments rather than a static background color.